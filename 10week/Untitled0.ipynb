{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOGxAiCX4PltJE60BMLC36e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"eiIQjuYz2igT"},"source":["import tensorflow as tf\n","from numpy import mean\n","from numpy import std\n","from matplotlib import pyplot\n","from sklearn.model_selection import KFold\n","from keras.datasets import fashion_mnist\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.optimizers import SGD\n","\n","def load_dataset():\n","    # Read\n","    (trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n","    # Reshape\n","    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n","    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n","    # One hot encoding\n","    trainY = to_categorical(trainY)\n","    testY = to_categorical(testY)\n","    return trainX, trainY, testX, testY\n","\n","def prep_pixels(train, test):\n","    # integers 에서 floats 으로 \n","    train_norm = train.astype('float32')\n","    test_norm = test.astype('float32')\n","    # Normalization\n","    train_norm = train_norm / 255.0\n","    test_norm = test_norm / 255.0\n","    # 출력\n","    return train_norm, test_norm\n","\n","def define_model():\n","    model = Sequential()\n","    model.add(Conv2D(64, (3, 3), padding='same', activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n","    model.add(MaxPooling2D((2, 2)))\n","    model.add(Dropout(0.25)) # dropoout code\n","    model.add(Flatten())\n","    model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n","    model.add(Dense(10, activation='softmax'))\n","    # 학습 설정 (compile)\n","    opt = SGD(lr=0.01, momentum=0.9)\n","    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model\n","\n","def evaluate_model(dataX, dataY, n_folds=5):\n","    scores, histories = list(), list()\n","    # cross validation 설정\n","    kfold = KFold(n_folds, shuffle=True, random_state=1)\n","    # training data 를 분할\n","    for train_ix, test_ix in kfold.split(dataX):\n","        model = define_model()\n","        # training set 과 test set 을 위한 행 선택\n","        trainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n","        # 훈련\n","\n","        earlystopper = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1) # EarlyStopper code loss감소가 10번 이상 미발생이면 stop\n","        history = model.fit(trainX,trainY, epochs=10, validation_data=(testX, testY), callbacks=[earlystopper])\n","\n","\n","        # 모델 평가\n","        _, acc = model.evaluate(testX, testY, verbose=0)\n","        print('> %.3f' % (acc * 100.0))\n","        # 평과 결과 기록\n","        scores.append(acc)\n","        histories.append(history)\n","    return scores, histories\n","\n","def summarize_diagnostics(histories):\n","    for i in range(len(histories)):\n","        # loss\n","        pyplot.subplot(211)\n","        pyplot.title('Cross Entropy Loss')\n","        pyplot.plot(histories[i].history['loss'], color='blue', label='train')\n","        pyplot.plot(histories[i].history['val_loss'], color='orange', label='test')\n","        # accuracy\n","        pyplot.subplot(212)\n","        pyplot.title('Classification Accuracy')\n","        pyplot.plot(histories[i].history['accuracy'], color='blue', label='train')\n","        pyplot.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n","    pyplot.show()\n","\n","def summarize_performance(scores):\n","    print('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n","    pyplot.boxplot(scores)\n","    pyplot.show()\n","\n","def run_test():\n","    trainX, trainY, testX, testY = load_dataset()\n","    trainX, testX = prep_pixels(trainX, testX)\n","    scores, histories = evaluate_model(trainX, trainY,5)\n","    summarize_diagnostics(histories)\n","    summarize_performance(scores)\n","\n","\n","run_test()"],"execution_count":null,"outputs":[]}]}